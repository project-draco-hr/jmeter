{
  System.out.println("Robot Crawler v" + Parser.getVersion());
  if (args.length < 2 || args[0].equals("-help")) {
    System.out.println();
    System.out.println("Syntax : java -classpath htmlparser.jar org.htmlparser.parserapplications.Robot <resourceLocn/website> <depth>");
    System.out.println();
    System.out.println("   <resourceLocn> the name of the file to be parsed (with complete path ");
    System.out.println("                  if not in current directory)");
    System.out.println("   <depth> No of links to be followed from each link");
    System.out.println("   -help This screen");
    System.out.println();
    System.out.println("HTML Parser home page : http://htmlparser.sourceforge.net");
    System.out.println();
    System.out.println("Example : java -classpath htmlparser.jar com.kizna.parserapplications.Robot http://www.google.com 3");
    System.out.println();
    System.out.println("If you have any doubts, please join the HTMLParser mailing list (user/developer) from the HTML Parser home page instead of mailing any of the contributors directly. You will be surprised with the quality of open source support. ");
    System.exit(-1);
  }
  String resourceLocation="";
  int crawlDepth=1;
  if (args.length != 0)   resourceLocation=args[0];
  if (args.length == 2)   crawlDepth=Integer.valueOf(args[1]).intValue();
  Robot robot=new Robot(resourceLocation);
  System.out.println("Crawling Site " + resourceLocation);
  try {
    robot.crawl(crawlDepth);
  }
 catch (  ParserException e) {
    e.printStackTrace();
  }
}
